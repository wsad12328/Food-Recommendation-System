\color{blue}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{img/Model.pdf} % 替換成你的圖片檔案
    \caption{模型架構圖}
    \label{fig:cross-column}
\end{figure*}

\section{Proposed}
\subsection{Data Preprocessing}
    \begin{figure}[tbh]
        \centering
        \includegraphics[width=0.5\textwidth]{img/preprocess.pdf}
        \caption{資料前處理架構圖}
        \label{fig-preprocess}
    \end{figure}
    本研究的資料前處理架構如 \xfig{fig-preprocess} 所示，利用爬蟲技術從 Foodpanda 和 Google Maps 獲取餐廳資料。每間餐廳的資料涵蓋了餐廳名稱、餐廳類型、評分以及顧客的評論。由於每家店通常會累積大量的評論，這些評論內容對於描述店家的品質、服務及顧客的體驗具有高度相關性。若將所有評論合併後再丟入大規模語言模型（LLM）進行分析，可能會因評論主題多樣性導致訊息混雜，進而影響模型的微調（Fine Tuning）效果。當不同主題的評論一起進行訓練時，模型可能難以識別每個特徵的意圖，進而影響結果的精準度。

    為提升模型的針對性，本研究首先將評論依主題分為三類：餐點品質、店內環境氣氛，以及兩者皆有的綜合評價。針對這三類評論，我們分別對每一類進行獨立的 LLM 微調。這種獨立的微調方法有助於每個模型專注於該主題的特徵，避免不同主題之間的訊息干擾。對於餐點品質類評論，模型學習專注於食物的口感、質量及呈現；對於店內環境氣氛的評論，模型則聚焦在用餐氛圍、環境設計及舒適度等描述上；而綜合評價類別則幫助模型掌握顧客的整體體驗。通過分開微調，每個模型能精確捕捉該主題的特徵表現，使得每一類評論的處理結果更具針對性。

    完成初步主題分類與獨立微調後，針對每一類主題中的評論再進行情感分析，以判斷其情感取向為正面或負面。這一分層且分主題的處理架構，能夠生成更為精確的特徵向量，使得每條評論的語意信息充分表達，進一步提升了推薦系統的精準度和可靠性。

\subsection{Model}
    \subsubsection{Single Embedding Layer}
        本研究所採用的NIE-GCN\cite{NIE-GCN}~模型可拆解成幾個主要步驟，首先是對餐廳節點進行向量嵌入。第一步會針對每個餐廳節點 $i$ 生成一個嵌入向量 $e_i$，此向量位於 $d$ 維空間中，即 $e_i \in \mathbb{R}^d$。在嵌入過程中，所有餐廳節點的嵌入向量會被收集成一組矩陣 $E_I^{(0)}$，此矩陣表達了所有餐廳節點的初始嵌入狀態，如下式所示： 
        \begin{equation} 
            E_I^{(0)} = {e_{i_1}^{(0)}, e_{i_2}^{(0)},\cdots,e_{i_N}^{(0)}} \in \mathbb{R}^{N \times d}, 
        \end{equation}
        其中，$N$ 代表餐廳節點的總數，而 $d$ 則是嵌入向量的維度；上標 $0$ 表示第 0 層傳播的初始狀態。藉由得到每個餐廳節點的嵌入向量後，模型便可利用這些向量作為基礎，來進一步推斷每位使用者的偏好。因為每個使用者節點 $u$ 的鄰居必定為餐廳節點，故模型會透過與該使用者互動過的餐廳節點來推敲其個人喜好。

        在完成餐廳節點的嵌入後，第二步則是建構每位使用者節點的初始嵌入向量 $e_u^{(0)}$。此過程需要依賴與使用者節點 $u$ 相鄰的餐廳節點 $i$ 的嵌入向量 $e_i^{(0)}$。第 0 層的嵌入構造方式如下： 
        \begin{equation} 
            e_u^{(0)} = \sigma \left(\sum_{i \in N_u} \frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}e_i^{(0)}\right), 
            \label{eq-e_u^0}
        \end{equation} 
        其中 $N_u$ 表示使用者節點 $u$ 的鄰居集合，而 $N_i$ 則代表餐廳節點 $i$ 的鄰居集合；$\sigma(\cdot)$ 是激活函數，選擇使用雙曲正切函數 (tanh)。透過這一層的加權平均，可以有效地融合使用者與其鄰近餐廳節點的特徵信息，以更準確地反映該使用者的行為特徵。

    \subsubsection{Propagation Layers}
    完成初始嵌入後，下一步是計算每個使用者節點 $u$ 與其相鄰的餐廳節點 $i$ 之間的注意力分數 $\rho(u, i)$，藉此衡量不同鄰居節點的重要性。該分數計算方式如下： 
    \begin{equation} 
        \rho(u, i) = Q^T\sigma(W(e_u^{(0)}||(e_i^{(0)})+b)), 
    \end{equation} 
    其中 $W \in \mathbb{R}^{2d \times d}$、$Q \in \mathbb{R}^{1 \times d}$、$b \in \mathbb{R}^{1 \times d}$，這三個參數分別為注意力機制中的權重矩陣與偏置項。此處的 $\sigma(\cdot)$ 同樣為雙曲正切函數 (tanh)，而 $||$ 則表示向量的串接操作。$\rho(u, i)$ 的分數越高，代表使用者 $u$ 與餐廳 $i$ 之間的關聯性越強。因此，透過該分數可以量化每個餐廳節點對於預測使用者偏好的貢獻度。

    為將注意力分數限制在 $[0,1]$ 的範圍內，利用 Softmax 函數對這些分數進行範圍歸一化處理，得到最終的注意力值 $\alpha(u, i)$。公式如下： \begin{equation} \alpha(u, i) = \frac{\exp(\rho(u, i))}{\left(\sum_{j \in N_u}\exp(\rho(u, j))\right)^{\beta}}. \end{equation} 其中 $\alpha(u, i)$ 代表了使用者節點 $u$ 與餐廳節點 $i$ 之間的最終注意力值。透過~$\alpha(u, i)$，每個使用者節點均能依據其鄰居的特徵，綜合考量注意力分數來完成向量更新。


    在初始嵌入狀態完成後，為進行更深層的特徵傳播，使用者節點 $u$ 的嵌入向量 $e_u^{(k)}$ 將在每一層根據其鄰居節點的資訊進行更新。使用者的嵌入向量 $e_u^{(k)}$ 的更新方式會依據先前計算出的注意力權重 $\alpha(u, i)$，並利用相鄰餐廳節點 $i$ 在上一層的嵌入向量 $e_i^{(k-1)}$ 進行加法聚合 (Add Aggregation)。此聚合方式可以有效融合鄰居的特徵信息，更新的計算公式如下： 
    \begin{equation} 
        e_u^{(k)} = \sigma\left(\sum_{i \in N_u} \alpha(u, i)e_i^{(k-1)}\right), 
    \end{equation} 
    其中，$\sigma(\cdot)$ 為雙曲正切函數 (tanh)，$N_u$ 表示使用者節點 $u$ 的鄰居集合。透過加權聚合，使用者節點可以自適應地調整對不同鄰居特徵的重視程度，進一步增強模型對於不同使用者偏好的捕捉能力。

    同樣地，初始狀態後的餐廳節點的嵌入向量 $e_i^{(k)}$ 也會根據其相鄰使用者節點的嵌入進行更新。這個更新方式與\xeq{eq-e_u^0}~類似，餐廳節點 $i$ 的嵌入向量會根據其相鄰的使用者節點 $u$ 的嵌入向量 $e_u^{(k)}$ 進行加權平均，計算方式如下： 
    \begin{equation} e_i^{(k)} = \sigma \left(\sum_{u \in N_i} \frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}} e_u^{(k)}\right), 
        \label{eq-e_i} 
    \end{equation} 其中，$N_u$ 和 $N_i$ 分別表示使用者節點 $u$ 和餐廳節點 $i$ 的鄰居集合，並透過加權平均來控制每個鄰居對於嵌入向量的貢獻。此\xeq{eq-e_i}~與\xeq{eq-e_u^0}~中的加權項 $\frac{1}{\sqrt{\vert N_u \vert \vert N_i \vert}}$ 可以平衡不同鄰居數量對嵌入更新的影響，從而避免由於鄰居數量不均而引起的偏差。藉由此加權項，每個餐廳節點的嵌入向量都將根據與其相鄰使用者的特徵進行有效更新，從而更準確地反映餐廳與使用者間的潛在關係。

    \subsubsection{Prediction Layers}
    在完成每一層使用者節點的嵌入向量 $e_u^{(k)}$ 和餐廳節點的嵌入向量 $e_i^{(k)}$ 的計算後，接下來的步驟是將這些嵌入向量進行聚合，以獲得最終的嵌入表達，在本研究將所有層的使用者嵌入向量和餐廳嵌入向量分別相加，計算公式如下： 
    \begin{equation} 
        e_u^* = \sum_{k=1}^{L} e_u^{(k)}, \quad e_i^* = \sum_{k=1}^{L} e_i^{(k)}, 
    \end{equation} 
    其中 $L$ 表示嵌入層的總數。這樣計算得到的 $e_u^*$ 和 $e_i^*$ 分別代表了使用者節點和餐廳節點的最終嵌入向量，這兩個向量綜合了多層的信息，能夠更全面地捕捉使用者與餐廳之間的潛在關聯。
    為了進一步評估使用者 $u$ 和餐廳 $i$ 之間的關聯性，將這兩個最終嵌入向量進行內積操作，為了將內積值限制在 0 到 1 的範圍內，引入了 S 型函數 (sigmoid function)，計算公式如下： 
    \begin{equation} 
        \hat{y_{ui}} = f(u, i) = \sigma(e_u^{T} e_i^), 
    \end{equation} 
    其中，$\hat{y_{ui}}$ 表示模型對於使用者 $u$ 和餐廳 $i$ 之間關聯性的預測結果。S 型函數 $\sigma(\cdot)$ 將內積的結果映射到 $[0, 1]$ 的範圍，使得模型的輸出可以被解釋為一個概率值，表達使用者 $u$ 對餐廳 $i$ 的喜好程度。

    \subsubsection{Model Optimization}
    待完成
\color{black}